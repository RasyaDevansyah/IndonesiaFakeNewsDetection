{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMYDIWA83yAq"
      },
      "source": [
        "# data collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tVrjrKE53cbT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vF7blhTj4H1T"
      },
      "outputs": [],
      "source": [
        "# train = pd.read_csv('Data_latih.csv')\n",
        "# test = pd.read_csv('Data_uji.csv')\n",
        "\n",
        "cnn_news = pd.read_excel('dataset_cnn_summarized.xlsx')\n",
        "kompas_news = pd.read_excel('dataset_kompas_summarized.xlsx')\n",
        "tempo_news = pd.read_excel('dataset_tempo_summarized.xlsx')\n",
        "hoax_news = pd.read_excel('dataset_turnbackhoax_summarized.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9630 entries, 0 to 9629\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   index                 9630 non-null   int64         \n",
            " 1   title                 9630 non-null   object        \n",
            " 2   raw timestamp         9630 non-null   object        \n",
            " 3   original              9630 non-null   object        \n",
            " 4   tags                  9627 non-null   object        \n",
            " 5   author                9630 non-null   object        \n",
            " 6   url                   9630 non-null   object        \n",
            " 7   cleaned               9630 non-null   object        \n",
            " 8   label                 9630 non-null   int64         \n",
            " 9   timestamp             9630 non-null   datetime64[ns]\n",
            " 10  cleaned token length  9630 non-null   int64         \n",
            " 11  summarized            9630 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(3), object(8)\n",
            "memory usage: 902.9+ KB\n"
          ]
        }
      ],
      "source": [
        "cnn_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4729 entries, 0 to 4728\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   index                 4729 non-null   int64         \n",
            " 1   title                 4729 non-null   object        \n",
            " 2   raw timestamp         4729 non-null   object        \n",
            " 3   original              4723 non-null   object        \n",
            " 4   tags                  4592 non-null   object        \n",
            " 5   author                4413 non-null   object        \n",
            " 6   url                   4729 non-null   object        \n",
            " 7   cleaned               4723 non-null   object        \n",
            " 8   label                 4729 non-null   int64         \n",
            " 9   timestamp             4729 non-null   datetime64[ns]\n",
            " 10  cleaned token length  4729 non-null   int64         \n",
            " 11  summarized            4547 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(3), object(8)\n",
            "memory usage: 443.5+ KB\n"
          ]
        }
      ],
      "source": [
        "kompas_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6592 entries, 0 to 6591\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   index                 6592 non-null   int64         \n",
            " 1   title                 6592 non-null   object        \n",
            " 2   raw timestamp         6592 non-null   object        \n",
            " 3   original              6592 non-null   object        \n",
            " 4   tags                  6591 non-null   object        \n",
            " 5   author                6592 non-null   object        \n",
            " 6   url                   6592 non-null   object        \n",
            " 7   cleaned               6592 non-null   object        \n",
            " 8   label                 6592 non-null   int64         \n",
            " 9   timestamp             6592 non-null   datetime64[ns]\n",
            " 10  cleaned token length  6592 non-null   int64         \n",
            " 11  summarized            6592 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(3), object(8)\n",
            "memory usage: 618.1+ KB\n"
          ]
        }
      ],
      "source": [
        "tempo_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10381 entries, 0 to 10380\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype         \n",
            "---  ------                --------------  -----         \n",
            " 0   index                 10381 non-null  int64         \n",
            " 1   title                 10381 non-null  object        \n",
            " 2   raw timestamp         10381 non-null  object        \n",
            " 3   original              10381 non-null  object        \n",
            " 4   tags                  10381 non-null  object        \n",
            " 5   author                10381 non-null  object        \n",
            " 6   url                   10381 non-null  object        \n",
            " 7   politik               10381 non-null  int64         \n",
            " 8   raw narasi            10381 non-null  object        \n",
            " 9   cleaned               6502 non-null   object        \n",
            " 10  label                 10381 non-null  int64         \n",
            " 11  timestamp             10381 non-null  datetime64[ns]\n",
            " 12  cleaned token length  10381 non-null  int64         \n",
            " 13  summarized            6166 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(4), object(9)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "hoax_news.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjL5hYWN30dk"
      },
      "source": [
        "# data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNaFJ9Lu45Hd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "cnn_news = cnn_news.drop(['index', 'title', 'raw timestamp', 'original', 'tags', 'author', 'url', 'cleaned', 'timestamp', 'cleaned token length'], axis=1)\n",
        "\n",
        "kompas_news = kompas_news.drop(['index', 'title', 'raw timestamp', 'original', 'tags', 'author', 'url', 'cleaned', 'timestamp', 'cleaned token length'], axis=1)\n",
        "\n",
        "tempo_news = tempo_news.drop(['index', 'title', 'raw timestamp', 'original', 'tags', 'author', 'url',  'cleaned', 'timestamp', 'cleaned token length'], axis=1)\n",
        "\n",
        "hoax_news = hoax_news.drop(['index', 'title', 'raw timestamp', 'original', 'tags', 'author', 'url', 'politik','raw narasi' ,  'cleaned', 'timestamp', 'cleaned token length'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9630 entries, 0 to 9629\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       9630 non-null   int64 \n",
            " 1   summarized  9630 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 150.6+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4729 entries, 0 to 4728\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       4729 non-null   int64 \n",
            " 1   summarized  4547 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 74.0+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6592 entries, 0 to 6591\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       6592 non-null   int64 \n",
            " 1   summarized  6592 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 103.1+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10381 entries, 0 to 10380\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       10381 non-null  int64 \n",
            " 1   summarized  6166 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 162.3+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None, None, None)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_news.info(), kompas_news.info(), tempo_news.info(), hoax_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9630 entries, 0 to 9629\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       9630 non-null   int64 \n",
            " 1   summarized  9630 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 150.6+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4547 entries, 0 to 4728\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       4547 non-null   int64 \n",
            " 1   summarized  4547 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 106.6+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6592 entries, 0 to 6591\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       6592 non-null   int64 \n",
            " 1   summarized  6592 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 103.1+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6166 entries, 0 to 10380\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       6166 non-null   int64 \n",
            " 1   summarized  6166 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 144.5+ KB\n"
          ]
        }
      ],
      "source": [
        "cnn_news = cnn_news.dropna(subset=['summarized'])\n",
        "cnn_news.info()\n",
        "\n",
        "kompas_news = kompas_news.dropna(subset=['summarized'])\n",
        "kompas_news.info()\n",
        "\n",
        "tempo_news = tempo_news.dropna(subset=['summarized'])\n",
        "tempo_news.info()\n",
        "\n",
        "\n",
        "hoax_news = hoax_news.dropna(subset=['summarized'])\n",
        "hoax_news.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6000 entries, 0 to 5999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       6000 non-null   int64 \n",
            " 1   summarized  6000 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 93.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# Sample equally from cnn_news, kompas_news, and tempo_news to total 10k (approx. 3333 each)\n",
        "n_each = 6000 // 3\n",
        "\n",
        "cnn_sample = cnn_news.sample(n=n_each, random_state=42)\n",
        "kompas_sample = kompas_news.sample(n=n_each, random_state=42)\n",
        "tempo_sample = tempo_news.sample(n=n_each, random_state=42)  # Adjust for rounding\n",
        "\n",
        "# Concatenate the samples\n",
        "combined_news = pd.concat([cnn_sample, kompas_sample, tempo_sample], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined dataframe\n",
        "combined_news = combined_news.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "combined_news.info()\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine combined_news (10k, mostly non-hoax) and hoax_news (10k, all hoax) for 20k train data\n",
        "train = pd.concat([\n",
        "    combined_news,\n",
        "    hoax_news.sample(n=6000, random_state=42)  # sample 10k hoax to balance\n",
        "], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined train data\n",
        "train = train.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_J27zJx6ILA",
        "outputId": "33cc3557-88bf-4432-8ef9-3b8d62726493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12000 entries, 0 to 11999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   label       12000 non-null  int64 \n",
            " 1   summarized  12000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 187.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    6000\n",
              "1    6000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.info()\n",
        "train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYMyqY0Z6SnX"
      },
      "source": [
        "## punct stopwords symbols lowercase stemming (data cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "gz1VPJ7EpzkE",
        "outputId": "1c5e9bed-ba51-4a92-a31c-7193504d2f8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Presiden Jokowi meminta relawan Bravo-5 yang d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Wakil walikota malang ini saya mau menyampaika...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Wawasan Nusantara benar diimplementasikan. Waw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Duta Besar Turki untuk Indonesia, Sander Gurbu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  Presiden Jokowi meminta relawan Bravo-5 yang d...\n",
              "1      1  Wakil walikota malang ini saya mau menyampaika...\n",
              "2      0  Wawasan Nusantara benar diimplementasikan. Waw...\n",
              "3      1  Duta Besar Turki untuk Indonesia, Sander Gurbu..."
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head(4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "0KWclu2c8I9d",
        "outputId": "062f8559-2cb9-47fe-dc7d-fb11b8013af9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Presiden, Jokowi, meminta, relawan, Bravo-5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Wakil, walikota, malang, ini, saya, mau, meny...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[Wawasan, Nusantara, benar, diimplementasikan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[Duta, Besar, Turki, untuk, Indonesia, ,, Sand...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [Presiden, Jokowi, meminta, relawan, Bravo-5, ...\n",
              "1      1  [Wakil, walikota, malang, ini, saya, mau, meny...\n",
              "2      0  [Wawasan, Nusantara, benar, diimplementasikan,...\n",
              "3      1  [Duta, Besar, Turki, untuk, Indonesia, ,, Sand..."
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize\n",
        "from nltk import word_tokenize\n",
        "# Fill NaN values with empty string to avoid TypeError during tokenization\n",
        "train[\"summarized\"] = train[\"summarized\"].fillna(\"\")\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(word_tokenize)\n",
        "train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "CUVW8DhZ6fUM",
        "outputId": "6da57080-5600-4058-f0f8-cfbf8f65ce28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Presiden, Jokowi, meminta, relawan, Bravo-5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Wakil, walikota, malang, ini, saya, mau, meny...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[Wawasan, Nusantara, benar, diimplementasikan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[Duta, Besar, Turki, untuk, Indonesia, Sander,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [Presiden, Jokowi, meminta, relawan, Bravo-5, ...\n",
              "1      1  [Wakil, walikota, malang, ini, saya, mau, meny...\n",
              "2      0  [Wawasan, Nusantara, benar, diimplementasikan,...\n",
              "3      1  [Duta, Besar, Turki, untuk, Indonesia, Sander,..."
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# punctuation -> nltk punkt\n",
        "\n",
        "import string\n",
        "\n",
        "def remove_punctuation(tokens):\n",
        "    return [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(remove_punctuation)\n",
        "train.head(4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXYXcyiz5d-K",
        "outputId": "9c6cbcd9-9922-4cd5-ce78-1ebf55a580df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx_trErn5c_T"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# stopwords -> https://rahmadya.com/2019/04/24/stopword-berbahasa-indonesia/\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "# Download NLTK English stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load English stopwords\n",
        "stopwords_english = set(stopwords.words('english'))\n",
        "\n",
        "# Load Indonesian stopwords from Sastrawi\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords_indonesia = set(factory.get_stop_words())\n",
        "\n",
        "# Combine both stopword lists\n",
        "combined_stopwords = stopwords_english.union(stopwords_indonesia)\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word.lower() not in combined_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "yrCwstfR6hDF",
        "outputId": "58bd8a80-40ad-4959-9351-03f5665c524a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Presiden, Jokowi, meminta, relawan, Bravo-5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Wakil, walikota, malang, mau, menyampaikan, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[Wawasan, Nusantara, benar, diimplementasikan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[Duta, Besar, Turki, Indonesia, Sander, Gurbuz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [Presiden, Jokowi, meminta, relawan, Bravo-5, ...\n",
              "1      1  [Wakil, walikota, malang, mau, menyampaikan, j...\n",
              "2      0  [Wawasan, Nusantara, benar, diimplementasikan,...\n",
              "3      1  [Duta, Besar, Turki, Indonesia, Sander, Gurbuz..."
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply to DataFrame\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(remove_stopwords)\n",
        "train.head(4)  # Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "bWWaMAcv7bcF",
        "outputId": "9e3dc7f6-5070-46c5-bc64-7404b49ca63d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Presiden, Jokowi, meminta, relawan, digawangi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Wakil, walikota, malang, mau, menyampaikan, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[Wawasan, Nusantara, benar, diimplementasikan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[Duta, Besar, Turki, Indonesia, Sander, Gurbuz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [Presiden, Jokowi, meminta, relawan, digawangi...\n",
              "1      1  [Wakil, walikota, malang, mau, menyampaikan, j...\n",
              "2      0  [Wawasan, Nusantara, benar, diimplementasikan,...\n",
              "3      1  [Duta, Besar, Turki, Indonesia, Sander, Gurbuz..."
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# symbols -> isalpha()\n",
        "def remove_symbols(tokens):\n",
        "    return [word for word in tokens if word.isalpha()]\n",
        "\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(remove_symbols)\n",
        "train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "gt4xmByG6h29",
        "outputId": "9af92f99-dfb0-4a6b-fc36-20434651a5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[presiden, jokowi, meminta, relawan, digawangi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[wakil, walikota, malang, mau, menyampaikan, j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[wawasan, nusantara, benar, diimplementasikan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[duta, besar, turki, indonesia, sander, gurbuz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [presiden, jokowi, meminta, relawan, digawangi...\n",
              "1      1  [wakil, walikota, malang, mau, menyampaikan, j...\n",
              "2      0  [wawasan, nusantara, benar, diimplementasikan,...\n",
              "3      1  [duta, besar, turki, indonesia, sander, gurbuz..."
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# case folding -> lower()\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(lambda tokens: [word.lower() for word in tokens])\n",
        "train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "igJB22kM6jIr",
        "outputId": "5fd14b71-7bdc-49c7-d526-17f112ff7410"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[presiden, jokowi, minta, rawan, gawang, luhut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[wakil, walikota, malang, mau, sampai, jajar, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[wawas, nusantara, benar, implementasi, wawas,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[duta, besar, turki, indonesia, sander, gurbuz...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  [presiden, jokowi, minta, rawan, gawang, luhut...\n",
              "1      1  [wakil, walikota, malang, mau, sampai, jajar, ...\n",
              "2      0  [wawas, nusantara, benar, implementasi, wawas,...\n",
              "3      1  [duta, besar, turki, indonesia, sander, gurbuz..."
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stemming -> https://pypi.org/project/Sastrawi/\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Initialize the stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "def stem_tokens(tokens):\n",
        "    # Join tokens into a sentence\n",
        "    sentence = ' '.join(tokens)\n",
        "    # Stem the sentence\n",
        "    stemmed_sentence = stemmer.stem(sentence)\n",
        "    # Split back into tokens\n",
        "    return stemmed_sentence.split()\n",
        "\n",
        "# Apply to the DataFrame\n",
        "train[\"summarized\"] = train[\"summarized\"].apply(stem_tokens)\n",
        "train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "27QSumdLLL8E"
      },
      "outputs": [],
      "source": [
        "train.to_csv('processed_data.csv', index=False)  # No row numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-KeKuGt5L0Tn"
      },
      "outputs": [],
      "source": [
        "#if processed data is lost\n",
        "\n",
        "train = pd.read_csv('processed_data.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQXlXuH98V9w"
      },
      "source": [
        "# more data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "858ocf-uL_xw",
        "outputId": "fca7db20-d0f8-4189-d61d-d0c8846a068e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>['presiden', 'jokowi', 'minta', 'rawan', 'gawa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>['wakil', 'walikota', 'malang', 'mau', 'sampai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>['wawas', 'nusantara', 'benar', 'implementasi'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>['duta', 'besar', 'turki', 'indonesia', 'sande...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized\n",
              "0      0  ['presiden', 'jokowi', 'minta', 'rawan', 'gawa...\n",
              "1      1  ['wakil', 'walikota', 'malang', 'mau', 'sampai...\n",
              "2      0  ['wawas', 'nusantara', 'benar', 'implementasi'...\n",
              "3      1  ['duta', 'besar', 'turki', 'indonesia', 'sande..."
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "# If text_processed column contains lists as strings, convert them back to lists\n",
        "def ensure_list(val):\n",
        "    if isinstance(val, str):\n",
        "        try:\n",
        "            return ast.literal_eval(val)\n",
        "        except Exception:\n",
        "            return []\n",
        "    return val\n",
        "\n",
        "\n",
        "train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TOHkBWDdNnmR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>summarized</th>\n",
              "      <th>text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>['presiden', 'jokowi', 'minta', 'rawan', 'gawa...</td>\n",
              "      <td>presiden jokowi minta rawan gawang luhut binsa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>['wakil', 'walikota', 'malang', 'mau', 'sampai...</td>\n",
              "      <td>wakil walikota malang mau sampai jajar staf se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>['wawas', 'nusantara', 'benar', 'implementasi'...</td>\n",
              "      <td>wawas nusantara benar implementasi wawas nusan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>['duta', 'besar', 'turki', 'indonesia', 'sande...</td>\n",
              "      <td>duta besar turki indonesia sander gurbuz beri ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>['institute', 'matang', 'rencana', 'diri', 'pa...</td>\n",
              "      <td>institute matang rencana diri partai serikat b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                         summarized  \\\n",
              "0      0  ['presiden', 'jokowi', 'minta', 'rawan', 'gawa...   \n",
              "1      1  ['wakil', 'walikota', 'malang', 'mau', 'sampai...   \n",
              "2      0  ['wawas', 'nusantara', 'benar', 'implementasi'...   \n",
              "3      1  ['duta', 'besar', 'turki', 'indonesia', 'sande...   \n",
              "4      0  ['institute', 'matang', 'rencana', 'diri', 'pa...   \n",
              "\n",
              "                                      text_processed  \n",
              "0  presiden jokowi minta rawan gawang luhut binsa...  \n",
              "1  wakil walikota malang mau sampai jajar staf se...  \n",
              "2  wawas nusantara benar implementasi wawas nusan...  \n",
              "3  duta besar turki indonesia sander gurbuz beri ...  \n",
              "4  institute matang rencana diri partai serikat b...  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['text_processed'] = train['summarized'].apply(ensure_list)\n",
        "\n",
        "# Now join tokens to form proper text\n",
        "train['text_processed'] = train['text_processed'].apply(lambda tokens: ' '.join(tokens))\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6K2E1bV8ZXO",
        "outputId": "9648e5f4-448e-4793-d833-c715344283e4"
      },
      "outputs": [],
      "source": [
        "# learn embedding/word vectorizing + feature extraction, see if one of them isnt needed n stuff karena my paper didnt use \"embedding\" -> *just learn how to use tf-idf*\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,  # Keep top 5000 words (adjust as needed)\n",
        "    min_df=2,           # Ignore words appearing in <2 docs\n",
        "    max_df=0.95,        # Ignore words in >95% of docs (remove common words)\n",
        "    ngram_range=(1, 2)  # Include 1-word and 2-word phrases (e.g., \"kota besar\")\n",
        ")\n",
        "\n",
        "# If train[\"FullText\"] contains lists of tokens, join them into strings for TF-IDF\n",
        "X_tfidf = tfidf.fit_transform(train[\"text_processed\"])\n",
        "\n",
        "\n",
        "# Convert to DataFrame (optional)\n",
        "# tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
        "# print(tfidf_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapV3B8a_MKK",
        "outputId": "c584cfec-f92a-44f1-87b0-2c6fd5f9a30f"
      },
      "outputs": [],
      "source": [
        "# split data for TRAIN\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_tfidf, train[\"label\"], test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKcOc9bb31ry"
      },
      "source": [
        "# modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UjRqgmyAGPn"
      },
      "source": [
        "https://www.kaggle.com/discussions/questions-and-answers/410405\n",
        "\n",
        "if you want an easy way out, just compare how multiple models function based on this one dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "also, kan harus pake metrics. bisa pake accuracy recall precision f-1 score yada yada. tapi di kaggle kan ada data_test or whatever, nah itu bisa dipake buat kayak manual testing. kayak use the models to guess if a certain row in the csv itu fake news or not. (if you do this, dont forget to make a function (or smth) to preprocess the single query you put in)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_unZIxx32rl"
      },
      "source": [
        "## naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKloRaehBcUD",
        "outputId": "410602bb-ce39-4441-a98a-e454d8e82f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91      1190\n",
            "           1       0.93      0.89      0.91      1210\n",
            "\n",
            "    accuracy                           0.91      2400\n",
            "   macro avg       0.91      0.91      0.91      2400\n",
            "weighted avg       0.91      0.91      0.91      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Naive_Bayes MultinomialNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na_n8oKPxs5I",
        "outputId": "2970faf4-b7ab-4271-ac67-ceb2d7a5c1ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['stopwords.joblib']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Saving Phase (run once) ===\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import joblib\n",
        "joblib.dump(model, 'multinomial_nb_model.joblib')\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.joblib')\n",
        "\n",
        "# Save preprocessing tools\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "joblib.dump(stemmer, 'stemmer.joblib')\n",
        "joblib.dump(combined_stopwords, 'stopwords.joblib')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TylgbT_gP70z",
        "outputId": "7a13ece1-6ee0-441b-81b9-3f81dca7a855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.80      0.85      1190\n",
            "           1       0.82      0.92      0.87      1210\n",
            "\n",
            "    accuracy                           0.86      2400\n",
            "   macro avg       0.87      0.86      0.86      2400\n",
            "weighted avg       0.87      0.86      0.86      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Naive_Bayes BernoulliNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFKJNUO5QFVs",
        "outputId": "134ce638-f36c-4bad-cd08-af274b41e4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92      1190\n",
            "           1       0.92      0.92      0.92      1210\n",
            "\n",
            "    accuracy                           0.92      2400\n",
            "   macro avg       0.92      0.92      0.92      2400\n",
            "weighted avg       0.92      0.92      0.92      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Naive_Bayes GaussianNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train.toarray(), y_train)\n",
        "y_pred = model.predict(X_test.toarray())\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the report\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPqTVC0738fE"
      },
      "source": [
        "## svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvTXtWs3Bd8Q",
        "outputId": "698de2e4-2546-4305-df18-66a283dd92fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95      1190\n",
            "           1       0.95      0.96      0.95      1210\n",
            "\n",
            "    accuracy                           0.95      2400\n",
            "   macro avg       0.95      0.95      0.95      2400\n",
            "weighted avg       0.95      0.95      0.95      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLsyr06W391U"
      },
      "source": [
        "## random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQul6IF3Bewf",
        "outputId": "33140522-3fc2-4d47-ec2d-638a2884c54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      1190\n",
            "           1       0.93      0.94      0.94      1210\n",
            "\n",
            "    accuracy                           0.94      2400\n",
            "   macro avg       0.94      0.93      0.93      2400\n",
            "weighted avg       0.94      0.94      0.93      2400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "okb3GGgGRjvO",
        "outputId": "23812f52-0f8d-4059-e3d6-13528fad5c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0    6000\n",
              "1    6000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['label'].value_counts()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
