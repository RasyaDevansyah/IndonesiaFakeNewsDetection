{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bf7b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install Sastrawi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24038f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4189df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, stemmer, stopwords):\n",
    "    # Tokenize\n",
    "    print(text)\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove punctuation and symbols\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "\n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # Join back into a string for TF-IDF\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce047ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seberat beratnya Pekerjaan Akan terasa ringan Bila tidak di kerjakan\n",
      "berat berat kerja asa ringan bila kerja\n",
      "Prediction: Fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator BernoulliNB from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Loading & Predicting Phase ===\n",
    "def predict_fake_news(text):\n",
    "    # Load resources\n",
    "    model = joblib.load('bernoulli_nb_model.joblib')\n",
    "    tfidf = joblib.load('tfidf_vectorizer.joblib')\n",
    "    stemmer = joblib.load('stemmer.joblib')\n",
    "    stopwords = joblib.load('stopwords.joblib')\n",
    "\n",
    "    # Preprocess\n",
    "    processed_text = preprocess_text(text, stemmer, stopwords)\n",
    "    print(processed_text)\n",
    "    X_new = tfidf.transform([processed_text])\n",
    "\n",
    "    # Predict\n",
    "    return model.predict(X_new)[0]\n",
    "\n",
    "# Test\n",
    "new_text = \"Seberat beratnya Pekerjaan Akan terasa ringan Bila tidak di kerjakan\"\n",
    "print(\"Prediction:\", \"Fake\" if predict_fake_news(new_text) == 1 else \"Real\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
